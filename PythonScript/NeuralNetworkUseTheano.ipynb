{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import matplotlib\n",
    "import pydot\n",
    "import graphviz\n",
    "import pydot\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from IPython.display import Image\n",
    "from IPython.display import SVG\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x8a749d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate dataset\n",
    "np.random.seed(0)\n",
    "train_X, train_y = sklearn.datasets.make_moons(200, noise = 0.2)\n",
    "train_X = train_X.astype(np.float32)\n",
    "train_y = train_y.astype(np.int32)\n",
    "plt.scatter(train_X[:,0], train_X[:,1], s = 40, c = train_y, cmap = plt.cm.Spectral)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to plot a decision boundary.\n",
    "# If you don't fully understand this function don't worry, it just generates the contour plot.\n",
    "def plot_decision_boundary(pred_func):\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = train_X[:, 0].min() - .5, train_X[:, 0].max() + .5\n",
    "    y_min, y_max = train_X[:, 1].min() - .5, train_X[:, 1].max() + .5\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole gid\n",
    "    Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(train_X[:, 0], train_X[:, 1], c=train_y, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Size definitions\n",
    "num_examples = len(train_X) # training set size\n",
    "nn_input_dim = 2 # input layer dimensionality\n",
    "nn_output_dim = 2 # output layer dimensionality\n",
    "nn_hdim = 100 # hiden layer dimensionality\n",
    "\n",
    "# Gradient descent parameters (I picked these by hand)\n",
    "epsilon = 0.01 # learning rate for gradient descent\n",
    "reg_lambda = 0.01 # regularization strength "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define variable using theano\n",
    "X = T.matrix('X')\n",
    "y = T.lvector('y')\n",
    "\n",
    "(X * 2).eval({X:[[1,1],[2,2]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define shared variable in theano: these are shared variable. Do not need to redefine them \n",
    "#with theano\n",
    "W1 = theano.shared(np.random.randn(nn_input_dim, nn_hdim), name = 'W1')\n",
    "b1 = theano.shared(np.zeros(nn_hdim),name = 'b1')\n",
    "W2 = theano.shared(np.random.randn(nn_hdim, nn_output_dim),name = 'W2')\n",
    "b2 = theano.shared(np.zeros(nn_output_dim),name = 'b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Forward propogation: only expression is defined here\n",
    "# It is not evaluated here\n",
    "z1 = X.dot(W1) + b1\n",
    "a1 = T.tanh(z1)\n",
    "z2 = a1.dot(W2) + b2\n",
    "y_hat = T.nnet.softmax(z2)\n",
    "\n",
    "#The regularization term\n",
    "loss_reg = 1./num_examples * reg_lambda/2*(T.sum(T.sqr(W1)) + T.sum(T.sqr(W2)))\n",
    "#total loss function\n",
    "loss = T.nnet.categorical_crossentropy(y_hat, y).mean() + loss_reg\n",
    "\n",
    "#Return a class prediction\n",
    "prediction = T.argmax(y_hat, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Thean functions that can be called from our python code\n",
    "#First parameter: if the true value of the variables used in the expression, which \n",
    "# is given by the second argument\n",
    "forward_prop = theano.function([X], y_hat)\n",
    "calculate_loss = theano.function([X,y],loss)\n",
    "predict = theano.function([X],prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Visualize the computational graph\n",
    "theano.printing.pydotprint(forward_prop, var_with_name_simple = True, compact = True, \n",
    "                           outfile = 'img/nn-theano-forward_prop.png', format = 'png')\n",
    "\n",
    "SVG(theano.printing.pydotprint(forward_prop, var_with_name_simple = True, compact = True, return_image = True, \n",
    "                              format = 'svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Print out the textual description of the computational graph\n",
    "theano.printing.debugprint(forward_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining the gradient of the expression\n",
    "#First argument is the loss function, the second is the parameter with respect to which you want to take the deritative\n",
    "dW2 = T.grad(loss, W2)\n",
    "db2 = T.grad(loss, b2)\n",
    "dW1 = T.grad(loss, W1)\n",
    "db1 = T.grad(loss, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Update the variables using theano\n",
    "gradient_step = theano.function(\n",
    "[X,y], updates = ((W2, W2 - epsilon*dW2),\n",
    "                 (W1, W1 - epsilon*dW1),\n",
    "                 (b2, b2 - epsilon*db2),\n",
    "                 (b1, b1 - epsilon*db1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Train a neural network with the gradient_step funtion\n",
    "\n",
    "def build_model(num_passes = 20000, print_loss = False):\n",
    "    np.random.seed(0)\n",
    "    W1.set_value(np.random.randn(nn_input_dim, nn_hdim) / np.sqrt(nn_input_dim))\n",
    "    b1.set_value(np.zeros(nn_hdim))\n",
    "    W2.set_value(np.random.randn(nn_hdim, nn_output_dim) / np.sqrt(nn_hdim))\n",
    "    b2.set_value(np.zeros(nn_output_dim))\n",
    "    \n",
    "    #Gradient descent \n",
    "    for i in xrange(0, num_passes):\n",
    "        gradient_step(train_X, train_y)\n",
    "        \n",
    "        if print_loss and i % 1000 == 0:\n",
    "            print \"Loss after iteration %i = %f\" %(i, calculate_loss(train_X, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build a model with a 3- dimensional hidden layer\n",
    "build_model(print_loss = True)\n",
    "\n",
    "plot_decision_boundary(lambda x : predict(x))\n",
    "plt.title(\"Decision Boundary for the hidden layer size 3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
